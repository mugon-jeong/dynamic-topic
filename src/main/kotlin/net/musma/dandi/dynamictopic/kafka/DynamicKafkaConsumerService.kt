package net.musma.dandi.dynamictopic.kafka

import io.github.oshai.kotlinlogging.KotlinLogging
import jakarta.annotation.PostConstruct
import net.musma.dandi.dynamictopic.domain.PipelineRepository
import org.apache.kafka.clients.consumer.ConsumerConfig
import org.apache.kafka.clients.consumer.ConsumerRebalanceListener
import org.apache.kafka.clients.consumer.ConsumerRecord
import org.apache.kafka.clients.producer.KafkaProducer
import org.apache.kafka.clients.producer.ProducerConfig
import org.apache.kafka.clients.producer.ProducerRecord
import org.apache.kafka.common.TopicPartition
import org.apache.kafka.common.serialization.StringDeserializer
import org.apache.kafka.common.serialization.StringSerializer
import org.springframework.kafka.core.DefaultKafkaConsumerFactory
import org.springframework.kafka.listener.ConcurrentMessageListenerContainer
import org.springframework.kafka.listener.ContainerProperties
import org.springframework.kafka.listener.MessageListener
import org.springframework.stereotype.Service
import java.util.Properties
import java.util.concurrent.ConcurrentHashMap

private val logger = KotlinLogging.logger {}

@Service
class DynamicKafkaConsumerService(
    private val kafkaProperties: KafkaProperties,
    private val pipelineRepository: PipelineRepository
) {
    private val containers = ConcurrentHashMap<ConsumerKey, ConcurrentMessageListenerContainer<String, String>>()
    private val activeConsumers = ConcurrentHashMap<ConsumerKey, Boolean>() // âœ… êµ¬ë… ìƒíƒœ ì¶”ì 

    @PostConstruct
    fun initializeConsumers() {
        logger.info { "ğŸ”„ ì„œë²„ ì‹œì‘ ì‹œ Kafka ì»¨ìŠˆë¨¸ ì´ˆê¸°í™” ì¤‘..." }

        val allPipelines = pipelineRepository.findAll()
        allPipelines.forEach { pipeline ->
            val groupId = pipeline.groupId
            val topics = pipeline.getTopics()

            topics.forEach { topic ->
                val consumerKey = ConsumerKey(groupId, topic)
                startListening(consumerKey) { receive ->
                    logger.info { "ğŸ“¨ [$topic] ë°›ì€ ë©”ì‹œì§€: $receive" }

                    val nextTopic = topics.getOrNull(topics.indexOf(topic) + 1)
                    if (nextTopic != null) {
                        sendMessage(nextTopic, receive)
                        logger.info { "â¡ï¸ ë©”ì‹œì§€ [$receive] ë¥¼ [$topic] â†’ [$nextTopic] ë¡œ ì „ë‹¬" }
                    } else {
                        logger.info { "âœ… ìµœì¢… í† í”½ [$topic] ì— ë„ì°©: $receive" }
                    }
                }
            }
        }

        logger.info { "âœ… ëª¨ë“  Kafka ì»¨ìŠˆë¨¸ ìë™ ë“±ë¡ ì™„ë£Œ" }
    }

    /**
     * âœ… í† í”½ êµ¬ë… ì‹œì‘
     */
    fun startListening(consumerKey: ConsumerKey, onMessage: (String) -> Unit) {
        val (groupId, topic) = consumerKey
        if (containers.containsKey(consumerKey)) {
            logger.info { "ğŸŸ¢ ê¸°ì¡´ ì»¨ìŠˆë¨¸ ì‚¬ìš©: $consumerKey" }
            return
        }

        val containerProperties = createContainerProperties(topic, consumerKey, onMessage)
        val consumerFactory = DefaultKafkaConsumerFactory<String, String>(createConsumerProperties(groupId))
        val container = ConcurrentMessageListenerContainer(consumerFactory, containerProperties)

        container.start()
        containers[consumerKey] = container
        activeConsumers[consumerKey] = false // ì´ˆê¸°ì— false ì„¤ì •
        logger.info { "ğŸ”„ Kafka ì»¨ìŠˆë¨¸ê°€ [$topic] êµ¬ë… ì¤‘... (groupId: $groupId)" }
    }

    /**
     * âœ… í† í”½ êµ¬ë… ì¤‘ì§€
     */
    fun stopListening(topic: String, groupId: String) {
        val consumerKey = ConsumerKey(groupId, topic)
        try {
            val container = containers[consumerKey]
            if (container != null) {
                container.stop()
                if (!container.isRunning) { // âœ… ì»¨ìŠˆë¨¸ê°€ ì™„ì „íˆ ì¤‘ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸ í›„ ì œê±°
                    containers.remove(consumerKey)
                    activeConsumers.remove(consumerKey)
                    logger.info { "ğŸ›‘ í† í”½ [$topic] êµ¬ë… ì¤‘ì§€ ì™„ë£Œ (groupId: $groupId)" }
                } else {
                    logger.warn { "âš ï¸ ì»¨ìŠˆë¨¸ ì¤‘ì§€ í™•ì¸ í•„ìš” [$topic] (groupId: $groupId)" }
                }
            } else {
                logger.warn { "âš ï¸ êµ¬ë… ì¤‘ì´ ì•„ë‹Œ í† í”½ [$topic] (groupId: $groupId)" }
            }
        } catch (e: Exception) {
            logger.error(e) { "âŒ í† í”½ [$topic] êµ¬ë… ì¤‘ì§€ ì‹¤íŒ¨ (groupId: $groupId)" }
        }
    }

    /**
     * âœ… ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
     */
    private fun createContainerProperties(
        topic: String,
        consumerKey: ConsumerKey,
        onMessage: (String) -> Unit
    ): ContainerProperties {
        return ContainerProperties(topic).apply {
            setConsumerRebalanceListener(
                object : ConsumerRebalanceListener {
                    override fun onPartitionsAssigned(partitions: MutableCollection<TopicPartition>) {
                        logger.info { "âœ… Kafka íŒŒí‹°ì…˜ í• ë‹¹ ì™„ë£Œ! Topic: $topic, Assigned Partitions: $partitions" }
                        activeConsumers[consumerKey] = true
                    }

                    override fun onPartitionsRevoked(partitions: MutableCollection<TopicPartition>) {
                        logger.warn { "âš ï¸ Kafka íŒŒí‹°ì…˜ íšŒìˆ˜ë¨! Topic: $topic, Revoked Partitions: $partitions" }
                        activeConsumers[consumerKey] = false
                    }
                },
            )

            /**
             * âœ… ë©”ì‹œì§€ ì²˜ë¦¬ ë¡œì§
             */
            messageListener = MessageListener { record ->
                handleMessage(record, consumerKey, onMessage)
            }
        }
    }

    /**
     * âœ… ë©”ì‹œì§€ ì²˜ë¦¬ (ì „ì²˜ë¦¬ í›„ ì „ë‹¬)
     */
    private fun handleMessage(record: ConsumerRecord<String, String>, consumerKey: ConsumerKey, onMessage: (String) -> Unit) {
        val maxWaitTimeMillis = 5000L  // ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (5ì´ˆ)
        val intervalMillis = 100L       // ì²´í¬ ê°„ê²© (100ms)
        var waitedTime = 0L

        // âœ… activeConsumers[consumerKey] ê°€ trueê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        while (activeConsumers[consumerKey] != true) {
            logger.warn { "â³ ë©”ì‹œì§€ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘: [$consumerKey] í™œì„±í™” ëŒ€ê¸° ì¤‘... -> ${record.value()}" }
            if (waitedTime >= maxWaitTimeMillis) {
                logger.warn { "âš ï¸ ë©”ì‹œì§€ ì²˜ë¦¬ ì§€ì—°: [$consumerKey] í™œì„±í™” ëŒ€ê¸° ì´ˆê³¼ (ë©”ì‹œì§€ íê¸° ê°€ëŠ¥ì„± ìˆìŒ) -> ${record.value()}" }
                return // ë©”ì‹œì§€ íê¸° (or ëŒ€ê¸° ì´ˆê³¼ ì‹œ ì²˜ë¦¬ ë°©ë²• ê²°ì • ê°€ëŠ¥)
            }

            Thread.sleep(intervalMillis)  // 100ms ëŒ€ê¸° í›„ ë‹¤ì‹œ í™•ì¸
            waitedTime += intervalMillis
        }

        // âœ… ì •ìƒì ìœ¼ë¡œ í™œì„±í™” í›„ ë©”ì‹œì§€ ì²˜ë¦¬
        try {
            val processedMessage = processMessage(record)
            onMessage(processedMessage) // âœ… ë©”ì‹œì§€ ì „ë‹¬ í›„ ì½œë°± ì‹¤í–‰
        } catch (e: Exception) {
            logger.error(e) { "âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: ${record.value()}" }
        }
    }

    /**
     * âœ… ë©”ì‹œì§€ ì „ì²˜ë¦¬
     */
    private fun processMessage(record: ConsumerRecord<String, String>): String {
        logger.info { "ğŸ“© [${record.topic()}] ë©”ì‹œì§€ ìˆ˜ì‹ : ${record.value()}" }
        return record.value()
    }

    /**
     * âœ… ë©”ì‹œì§€ ë°œí–‰
     */
    fun sendMessage(topic: String, message: String) {
        KafkaProducer<String, String>(createProducerProperties()).use { producer ->
            producer.send(ProducerRecord(topic, message))
            logger.info { "ğŸ“¤ ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ: [$message] â†’ [$topic]" }
        }
    }

    /**
     * âœ… Kafka ì»¨ìŠˆë¨¸ ì„¤ì •
     */
    private fun createConsumerProperties(groupId: String) = mapOf(
        ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to kafkaProperties.bootstrapServers,
        ConsumerConfig.GROUP_ID_CONFIG to groupId,
        ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java.name,
        ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to StringDeserializer::class.java.name,
        ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to kafkaProperties.consumer.autoOffsetReset,
        ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to kafkaProperties.consumer.enableAutoCommit,
        ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG to kafkaProperties.properties.request.timeoutMs,
        ConsumerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG to kafkaProperties.properties.connections.maxIdleMs,
        ConsumerConfig.METADATA_MAX_AGE_CONFIG to "10000",
        ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG to "10000",
    )

    /**
     * âœ… Kafka í”„ë¡œë“€ì„œ ì„¤ì •
     */
    private fun createProducerProperties(): Properties {
        return Properties().apply {
            put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.bootstrapServers)
            put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer::class.java.name)
            put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer::class.java.name)
        }
    }

    /**
     * âœ… í˜„ì¬ í™œì„±í™”ëœ êµ¬ë… ìƒíƒœ ì¡°íšŒ
     */
    fun getConsumerStatus(): Map<ConsumerKey, Boolean> = activeConsumers.toMap()

    /**
     * âœ… ê¸°ì¡´ ì»¨ìŠˆë¨¸ ê°€ì ¸ì˜¤ê¸°
     */
    fun getContainer(consumerKey: ConsumerKey): ConcurrentMessageListenerContainer<String, String>? {
        return containers[consumerKey]
    }

    /**
     * âœ… ê¸°ì¡´ ì»¨ìŠˆë¨¸ì˜ ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆ ë³€ê²½
     */
    fun setOnMessageListener(consumerKey: ConsumerKey, onMessage: (String) -> Unit) {
        val container = getContainer(consumerKey)
        if (container != null) {
            logger.info { "ğŸ”„ ì»¨ìŠˆë¨¸ [$consumerKey]ì˜ ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆ ì—…ë°ì´íŠ¸" }
            container.containerProperties.messageListener = MessageListener { record ->
                val processedMessage = processMessage(record)
                onMessage(processedMessage)
            }
        } else {
            logger.warn { "âš ï¸ ì»¨ìŠˆë¨¸ [$consumerKey] ì—†ìŒ. ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆ ì—…ë°ì´íŠ¸ ë¶ˆê°€" }
        }
    }
}